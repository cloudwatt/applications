heat_template_version: 2013-05-23

parameters:
  pool_id:
    label: pool id
    type: string
  nodename:
    label: nodename
    type: string
  nodeip:
    label: nodename
    type: string
  subnet:
    label: subnet
    type: string
  stack:
    label: stack
    type: string
  os_username:
    label: os_username
    type: string
  os_password:
    label: os_password
    type: string
  os_tenant:
    label: os_tenant
    type: string
  os_tenant_id:
    label: os_tenant_id
    type: string
  os_auth:
    label: os_auth
    type: string
  os_region:
    label: os_region
    type: string
  network:
    label: network
    type: string
  security_group:
    label: security_group
    type: string
  keypair_name:
    description: Keypair to inject in instance
    label: SSH Keypair
    type: string
  domain:
    description: Wildcarded domain, ex example.com must have a *.example.com DNS entry
    label: Cloud DNS
    type: string
  flavor_name:
    label: Instance Type (Flavor)
    description: Flavor to use for the deployed instance
    type: string

resources:
  port:
    type: OS::Neutron::Port
    properties:
      network: { get_param: network }
      fixed_ips:
        - ip_address: { get_param: nodeip }
          subnet_id: { get_param: subnet }
      security_groups:
        - { get_param: security_group }

  member:
    type: OS::Neutron::PoolMember
    properties:
      pool_id: {get_param: pool_id}
      address: {get_attr: [master , first_address]}
      protocol_port: 443

  master:
    type: OS::Nova::Server
    properties:
      key_name: { get_param: keypair_name }
      image: CoreOS Stable 899.13
      flavor: { get_param: flavor_name }
      user_data_format: RAW
      name: { get_param: nodename}
      networks:
        - port: { get_resource: port }
      user_data:
        str_replace:
          params:
            $private_ipv4: { get_attr: [ port, fixed_ips, 0, ip_address ] }
            $fqdn: { get_param: nodename }
            $public_ipv4: { get_attr: [floating_ip, floating_ip_address] }
            $domain: { get_param: domain }
            $stack: { get_param: stack }
            $os_username: { get_param: os_username}
            $os_password: { get_param: os_password}
            $os_tenant: { get_param: os_tenant }
            $os_auth: { get_param: os_auth }
            $os_region: { get_param: os_region }
            $os_project_id: { get_param: os_tenant_id }
            $subnet: { get_param: subnet }
          template: |
            #cloud-config
            write_files:
              - path: /etc/flannel/options.env
                permissions: 0644
                owner: "root:root"
                content: |
                  FLANNELD_IFACE=$private_ipv4
                  FLANNELD_ETCD_ENDPOINTS=http://localhost:2379
              - path: /opt/kubernetes-init-ssl.sh
                permissions: 0700
                owner: "root:root"
                content: |
                  #!/bin/bash
                  mkdir -p /etc/kubernetes/ssl
                  cd /etc/kubernetes/ssl
                  echo "Waiting for etcd..."
                  ETCD="http://$private_ipv4:2379"
                  until curl -s $ETCD/v2/keys/ssl/ca|grep CERTIFICATE
                  do
                      echo "Trying: $ETCD"
                      sleep 1
                  done
                  etcdctl get /ssl/ca > ca.pem
                  etcdctl get /ssl/key > ca-key.pem
                  etcdctl get /ssl/admin > admin.pem
                  etcdctl get /ssl/admin-key > admin-key.pem
                  etcdctl get /ssl/apiserver > apiserver.pem
                  etcdctl get /ssl/apiserver-key > apiserver-key.pem
                  # Set permissions
                  chmod 600 /etc/kubernetes/ssl/*-key.pem
                  chown root:root /etc/kubernetes/ssl/*-key.pem
              - path: /etc/kubernetes/cloud.conf
                permissions: 0766
                owner: "root:root"
                content: |
                  [Global]
                  auth-url=$os_auth
                  username=$os_username
                  password=$os_password
                  region=$os_region
                  tenant-id=$os_project_id
                  [LoadBalancer]
                  subnet-id = $subnet
              - path: /opt/kube-resources-init.sh
                permissions: 0700
                owner: "root:root"
                content: |
                  #!/bin/bash
                  # Secret
                  cat <<EOF > /etc/kubernetes/descriptors/0-secret.yaml
                  apiVersion: v1
                  kind: Secret
                  metadata:
                    name: openstack
                  type: Opaque
                  data:
                    password: $(echo -n '$os_password' | base64)
                    username: $(echo -n '$os_username' | base64)
                  EOF
                  echo "Waiting for Kubernetes API..."
                  K8S="http://$private_ipv4:8080"
                  until curl --silent "$K8S/version"
                  do
                      echo "Trying: $K8S"
                      sleep 1
                  done
                  RES=$(curl -H "Content-Type: application/json" -XPOST -d'{"apiVersion":"v1","kind":"Namespace","metadata":{"name":"kube-system"}}' "http://127.0.0.1:8080/api/v1/namespaces")
                  if [ -z "$(echo $RES | grep '"phase": "Active"')" ]; then
                      echo "Unexpected error configuring Kubernetes Namespace : $RES"
                  else
                      echo "Created kube-system namespace"
                  fi
                  mkdir -p /opt/bin
                  curl -o /opt/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.3.2/bin/linux/amd64/kubectl
                  chmod +x /opt/bin/kubectl
                  ret=$(/opt/bin/kubectl get secret openstack)
                  if [ "$?" -eq "1" ]; then
                    /opt/bin/kubectl create -f /etc/kubernetes/descriptors --validate=false
                  fi
              - path: /etc/kubernetes/manifests/kube-apiserver.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: Pod
                  metadata:
                    name: kube-apiserver
                    namespace: kube-system
                  spec:
                    hostNetwork: true
                    containers:
                    - name: kube-apiserver
                      image: quay.io/coreos/hyperkube:v1.3.2_coreos.0
                      command:
                      - /hyperkube
                      - apiserver
                      - --bind-address=0.0.0.0
                      - --insecure-bind-address=0.0.0.0
                      - --etcd-servers=http://$private_ipv4:2379
                      - --allow-privileged=true
                      - --service-cluster-ip-range=10.0.2.0/24
                      - --service-node-port-range=1-33000
                      - --secure-port=443
                      - --cloud-provider=openstack
                      - --cloud-config=/etc/kubernetes/cloud.conf
                      - --advertise-address=$private_ipv4
                      - --admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota
                      - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem
                      - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
                      - --client-ca-file=/etc/kubernetes/ssl/ca.pem
                      - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem
                      ports:
                      - containerPort: 443
                        name: https
                      - containerPort: 8080
                        name: local
                      volumeMounts:
                      - mountPath: /etc/kubernetes/ssl
                        name: ssl-certs-kubernetes
                        readOnly: true
                      - mountPath: /etc/kubernetes/cloud.conf
                        name: cloud-conf-kubernetes
                        readOnly: true
                      - mountPath: /etc/ssl/certs
                        name: ssl-certs-host
                        readOnly: true
                    volumes:
                    - hostPath:
                        path: /etc/kubernetes/ssl
                      name: ssl-certs-kubernetes
                    - hostPath:
                        path: /etc/kubernetes/cloud.conf
                      name: cloud-conf-kubernetes
                    - hostPath:
                        path: /usr/share/ca-certificates
                      name: ssl-certs-host
              - path: /etc/kubernetes/manifests/kube-proxy.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: Pod
                  metadata:
                    name: kube-proxy
                    namespace: kube-system
                  spec:
                    hostNetwork: true
                    containers:
                    - name: kube-proxy
                      image: quay.io/coreos/hyperkube:v1.3.2_coreos.0
                      command:
                      - /hyperkube
                      - proxy
                      - --master=http://127.0.0.1:8080
                      - --proxy-mode=iptables
                      securityContext:
                        privileged: true
                      volumeMounts:
                      - mountPath: /etc/ssl/certs
                        name: ssl-certs-host
                        readOnly: true
                    volumes:
                    - hostPath:
                        path: /usr/share/ca-certificates
                      name: ssl-certs-host
              - path: /etc/kubernetes/manifests/kube-controller-manager.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: Pod
                  metadata:
                    name: kube-controller-manager
                    namespace: kube-system
                  spec:
                    hostNetwork: true
                    containers:
                    - name: kube-controller-manager
                      image: quay.io/coreos/hyperkube:v1.3.2_coreos.0
                      command:
                      - /hyperkube
                      - controller-manager
                      - --master=http://127.0.0.1:8080
                      - --cloud-provider=openstack
                      - --cloud-config=/etc/kubernetes/cloud.conf
                      - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
                      - --pod-eviction-timeout=1m0s
                      - --root-ca-file=/etc/kubernetes/ssl/ca.pem
                      livenessProbe:
                        httpGet:
                          host: 127.0.0.1
                          path: /healthz
                          port: 10252
                        initialDelaySeconds: 15
                        timeoutSeconds: 1
                      volumeMounts:
                      - mountPath: /etc/kubernetes/ssl
                        name: ssl-certs-kubernetes
                        readOnly: true
                      - mountPath: /etc/kubernetes/cloud.conf
                        name: cloud-conf-kubernetes
                        readOnly: true
                      - mountPath: /etc/ssl/certs
                        name: ssl-certs-host
                        readOnly: true
                    volumes:
                    - hostPath:
                        path: /etc/kubernetes/ssl
                      name: ssl-certs-kubernetes
                    - hostPath:
                        path: /etc/kubernetes/cloud.conf
                      name: cloud-conf-kubernetes
                    - hostPath:
                        path: /usr/share/ca-certificates
                      name: ssl-certs-host
              - path: /etc/kubernetes/manifests/kube-scheduler.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: Pod
                  metadata:
                    name: kube-scheduler
                    namespace: kube-system
                  spec:
                    hostNetwork: true
                    containers:
                    - name: kube-scheduler
                      image: quay.io/coreos/hyperkube:v1.3.2_coreos.0
                      command:
                      - /hyperkube
                      - scheduler
                      - --master=http://127.0.0.1:8080
                      - --leader-elect=true
                      livenessProbe:
                        httpGet:
                          host: 127.0.0.1
                          path: /healthz
                          port: 10251
                        initialDelaySeconds: 15
                        timeoutSeconds: 1
              - path: /etc/kubernetes/descriptors/1-skydns.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: List
                  items:
                    - apiVersion: v1
                      kind: Service
                      metadata:
                        name: kube-dns
                        namespace: kube-system
                        labels:
                          k8s-app: kube-dns
                          kubernetes.io/cluster-service: "true"
                          kubernetes.io/name: "KubeDNS"
                      spec:
                        selector:
                          k8s-app: kube-dns
                        clusterIP: 10.0.2.2
                        ports:
                        - name: dns
                          port: 53
                          protocol: UDP
                        - name: dns-tcp
                          port: 53
                          protocol: TCP
                    - apiVersion: v1
                      kind: ReplicationController
                      metadata:
                        name: kube-dns-v15
                        namespace: kube-system
                        labels:
                          k8s-app: kube-dns
                          version: v15
                          kubernetes.io/cluster-service: "true"
                      spec:
                        replicas: 1
                        selector:
                          k8s-app: kube-dns
                          version: v15
                        template:
                          metadata:
                            labels:
                              k8s-app: kube-dns
                              version: v15
                              kubernetes.io/cluster-service: "true"
                          spec:
                            containers:
                            - name: kubedns
                              image: gcr.io/google_containers/kubedns-amd64:1.5
                              resources:
                                limits:
                                  cpu: 100m
                                  memory: 200Mi
                                requests:
                                  cpu: 100m
                                  memory: 100Mi
                              livenessProbe:
                                httpGet:
                                  path: /healthz
                                  port: 8080
                                  scheme: HTTP
                                initialDelaySeconds: 60
                                timeoutSeconds: 5
                                successThreshold: 1
                                failureThreshold: 5
                              readinessProbe:
                                httpGet:
                                  path: /readiness
                                  port: 8081
                                  scheme: HTTP
                                initialDelaySeconds: 30
                                timeoutSeconds: 5
                              args:
                              # command = "/kube-dns"
                              - --domain=$domain
                              - --dns-port=10053
                              ports:
                              - containerPort: 10053
                                name: dns-local
                                protocol: UDP
                              - containerPort: 10053
                                name: dns-tcp-local
                                protocol: TCP
                            - name: dnsmasq
                              image: gcr.io/google_containers/dnsmasq:1.1
                              args:
                              - --cache-size=1000
                              - --no-resolv
                              - --server=127.0.0.1#10053
                              ports:
                              - containerPort: 53
                                name: dns
                                protocol: UDP
                              - containerPort: 53
                                name: dns-tcp
                                protocol: TCP
                            - name: healthz
                              image: gcr.io/google_containers/exechealthz-amd64:1.0
                              resources:
                                # keep request = limit to keep this container in guaranteed class
                                limits:
                                  cpu: 10m
                                  memory: 20Mi
                                requests:
                                  cpu: 10m
                                  memory: 20Mi
                              args:
                              - -cmd=nslookup kubernetes.default.svc.$domain 127.0.0.1 >/dev/null
                              - -port=8080
                              ports:
                              - containerPort: 8080
                                protocol: TCP
                            dnsPolicy: Default  # Don't use cluster DNS.
              - path: /etc/environment
                permissions: 0666
                owner: "root:root"
                content: |
                  COREOS_PRIVATE_IPV4=$private_ipv4
                  COREOS_PUBLIC_IPV4=$public_ipv4
                  ETCD_ADDR=$private_ipv4:2379
                  ETCD_PEER_ADDR=$private_ipv4:2380

            coreos:
              etcd2:
                proxy: on
                listen-client-urls: http://0.0.0.0:2379
                initial-cluster: driver-0=http://10.0.1.240:2380,driver-1=http://10.0.1.241:2380,driver-2=http://10.0.1.242:2380
              units:
                - name: etcd2.service
                  command: start
                - name: flanneld.service
                  drop-ins:
                    - name: 40-ExecStartPre-symlink.conf
                      content: |
                        [Service]
                        ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env
                - name: docker.service
                  drop-ins:
                    - name: 40-flannel.conf
                      content: |
                        [Unit]
                        Requires=flanneld.service
                        After=flanneld.service
                - name: generatessl.service
                  command: start
                  content: |
                    [Unit]
                    Requires=etcd2.service
                    After=etcd2.service
                    ConditionPathExists=!/etc/kubernetes/ssl/apiserver.pem
                    Description=Kubernetes Keys Retriever

                    [Service]
                    Type=oneshot
                    ExecStart=/opt/kubernetes-init-ssl.sh
                - name: kubelet.service
                  command: start
                  content: |
                    [Unit]
                    Requires=generatessl.service
                    After=generatessl.service

                    [Service]
                    ExecStartPre=/usr/bin/mkdir -p /opt/bin
                    ExecStartPre=-/usr/bin/curl -o /opt/bin/kubelet -C - http://storage.googleapis.com/kubernetes-release/release/v1.3.2/bin/linux/amd64/kubelet
                    ExecStartPre=-/usr/bin/chmod +x /opt/bin/kubelet
                    ExecStart=/opt/bin/kubelet \
                      --api-servers=http://127.0.0.1:8080 \
                      --register-schedulable=false \
                      --register-node=true \
                      --cloud-provider=openstack \
                      --cloud-config=/etc/kubernetes/cloud.conf \
                      --allow-privileged=true \
                      --config=/etc/kubernetes/manifests \
                      --hostname-override=$fqdn \
                      --cluster-dns=10.0.2.2 \
                      --cluster-domain=$domain
                    ExecStartPost=-/opt/kube-resources-init.sh
                    Restart=always
                    RestartSec=10
                    [Install]
                    WantedBy=multi-user.target
                - name: settimezone.service
                  command: start
                  content: |
                    [Unit]
                    Description=Set the time zone

                    [Service]
                    ExecStart=/usr/bin/timedatectl set-timezone Europe/Paris
                    RemainAfterExit=yes
                    Type=oneshot

  floating_ip_link:
    type: OS::Nova::FloatingIPAssociation
    properties:
      floating_ip: { get_resource: floating_ip }
      server_id: { get_resource: master }

  floating_ip:
    type: OS::Neutron::FloatingIP
    properties:
      floating_network_id: 6ea98324-0f14-49f6-97c0-885d1b8dc517


outputs:
  public_ip:
    value: {get_attr: [floating_ip, floating_ip_address]}